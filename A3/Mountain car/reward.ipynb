{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "goal_steps = 200\n",
    "score_requirement = -198\n",
    "intial_games = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.2:   #self-defined\n",
    "                reward = 1\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-176.0, -186.0, -184.0, -192.0, -174.0, -192.0, -178.0, -180.0, -150.0, -196.0, -190.0, -192.0, -192.0, -176.0, -166.0, -168.0, -198.0, -186.0, -170.0, -172.0, -176.0, -188.0, -174.0, -194.0, -178.0, -190.0, -176.0, -182.0, -182.0, -182.0, -192.0, -198.0, -162.0, -188.0, -174.0, -198.0, -172.0, -184.0, -168.0, -186.0, -176.0, -180.0]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8358/8358 [==============================] - 2s 192us/step - loss: 0.2279\n",
      "Epoch 2/5\n",
      "8358/8358 [==============================] - 1s 101us/step - loss: 0.2225\n",
      "Epoch 3/5\n",
      "8358/8358 [==============================] - 1s 96us/step - loss: 0.2219\n",
      "Epoch 4/5\n",
      "8358/8358 [==============================] - 1s 132us/step - loss: 0.2214\n",
      "Epoch 5/5\n",
      "8358/8358 [==============================] - 1s 116us/step - loss: 0.2209\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -174.,\n",
       "       -173., -173., -172., -168., -166., -166., -166., -166., -166.,\n",
       "       -166., -165., -165., -165., -165., -164., -164., -164., -164.,\n",
       "       -164., -163., -163., -163., -163., -163., -163., -163., -163.,\n",
       "       -163., -163., -163., -163., -162., -157., -153., -153., -150.,\n",
       "       -144., -141., -140., -140., -138., -138., -138., -138., -137.,\n",
       "       -136., -136., -135., -135., -134., -134., -133., -133., -132.,\n",
       "       -132., -132., -132., -131., -131., -131., -131., -131., -130.,\n",
       "       -130., -129., -129., -129., -129., -129., -129., -129., -129.,\n",
       "       -129.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        # Uncomment this line if you want to see how our bot playing\n",
    "        # env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores1_order = np.sort(scores)\n",
    "avg_scores1 = sum(scores)/len(scores)\n",
    "scores1_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.1:  #self-defined\n",
    "                reward = 1\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-186.0, -190.0]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "398/398 [==============================] - 0s 314us/step - loss: 0.3061\n",
      "Epoch 2/5\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.2557\n",
      "Epoch 3/5\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.2323\n",
      "Epoch 4/5\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.2283\n",
      "Epoch 5/5\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.2270\n",
      "Wall time: 16.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        # Uncomment this line if you want to see how our bot playing\n",
    "        # env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores2_order = np.sort(scores)\n",
    "avg_scores2 = sum(scores)/len(scores)\n",
    "scores2_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.3:  #self-defined\n",
    "                reward = 1\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-174.0, -168.0, -180.0, -168.0, -188.0, -172.0, -178.0, -166.0, -160.0, -182.0, -168.0, -182.0, -178.0, -148.0, -164.0, -130.0, -178.0, -158.0, -190.0, -162.0, -168.0, -176.0, -198.0, -190.0, -186.0, -174.0, -188.0, -180.0, -180.0, -158.0, -178.0, -196.0, -166.0, -176.0, -156.0, -140.0, -160.0, -186.0, -174.0, -168.0, -154.0, -184.0, -184.0, -178.0, -170.0, -198.0, -186.0, -142.0, -190.0, -186.0, -196.0, -182.0, -190.0, -182.0, -194.0, -176.0, -172.0, -184.0, -188.0, -198.0, -184.0, -178.0, -192.0, -184.0, -150.0, -186.0, -186.0, -186.0, -166.0, -184.0, -188.0, -174.0, -172.0, -162.0, -198.0, -164.0, -190.0, -186.0, -188.0, -174.0, -172.0, -178.0, -162.0, -180.0, -156.0, -186.0, -170.0, -180.0, -192.0, -144.0, -176.0, -166.0, -180.0, -184.0, -160.0, -174.0, -164.0, -144.0, -174.0, -168.0, -168.0, -170.0, -188.0, -160.0, -178.0, -190.0, -174.0, -186.0, -188.0, -176.0, -190.0, -142.0, -176.0, -192.0, -180.0, -170.0, -186.0, -164.0, -166.0, -176.0, -186.0, -182.0, -182.0, -174.0, -168.0, -190.0, -186.0, -176.0, -146.0, -172.0, -172.0, -178.0, -172.0, -194.0, -138.0, -186.0, -152.0, -180.0, -198.0, -164.0, -184.0, -184.0, -172.0, -174.0, -174.0, -162.0, -174.0, -192.0, -156.0, -196.0, -170.0, -146.0, -198.0, -164.0, -158.0, -182.0, -174.0, -174.0, -168.0, -182.0, -188.0, -188.0, -180.0, -178.0, -188.0, -176.0, -172.0, -184.0, -192.0, -150.0, -186.0, -158.0, -180.0, -198.0, -176.0, -150.0, -164.0, -170.0, -188.0, -196.0, -170.0, -176.0, -168.0, -168.0, -192.0, -154.0, -166.0, -174.0, -182.0, -184.0, -176.0, -178.0, -166.0, -176.0, -184.0, -190.0, -178.0, -186.0, -156.0, -164.0, -172.0, -182.0, -184.0, -194.0, -158.0, -182.0, -192.0, -186.0, -170.0, -148.0, -172.0, -192.0, -168.0, -188.0, -182.0, -166.0, -170.0, -176.0, -172.0, -184.0, -182.0, -190.0, -162.0, -192.0, -176.0, -156.0, -180.0, -184.0, -154.0, -140.0, -194.0, -190.0, -166.0, -174.0, -178.0, -194.0, -180.0, -184.0, -188.0, -164.0, -170.0, -172.0, -178.0, -180.0, -188.0, -194.0, -156.0, -174.0, -170.0, -158.0, -174.0, -172.0, -168.0, -186.0, -180.0, -186.0, -182.0, -188.0, -184.0, -186.0, -186.0, -174.0, -186.0, -180.0, -162.0, -170.0, -182.0, -142.0, -198.0, -166.0, -178.0, -176.0, -186.0, -150.0, -182.0, -180.0, -196.0, -198.0, -198.0, -168.0, -178.0, -188.0, -174.0, -180.0, -172.0, -194.0, -164.0, -186.0, -166.0, -158.0, -188.0, -182.0, -170.0, -170.0, -182.0, -180.0, -188.0, -164.0, -182.0, -168.0, -172.0, -166.0, -196.0, -182.0, -178.0, -178.0, -190.0, -180.0, -176.0, -178.0, -180.0, -190.0, -194.0, -166.0, -192.0, -196.0, -188.0, -184.0, -186.0, -172.0, -178.0, -188.0, -190.0, -124.0, -146.0, -164.0, -148.0, -172.0, -182.0, -182.0, -120.0, -180.0, -170.0, -178.0, -180.0, -148.0, -182.0, -156.0, -196.0, -176.0, -188.0, -194.0, -172.0, -176.0, -174.0, -188.0, -168.0, -156.0, -174.0, -178.0, -190.0, -178.0, -184.0, -188.0, -184.0, -182.0, -192.0, -176.0, -188.0, -172.0, -198.0, -180.0, -192.0, -182.0, -174.0, -182.0, -172.0, -178.0, -182.0, -166.0, -178.0, -150.0, -186.0, -136.0, -194.0, -180.0, -198.0, -182.0, -196.0, -180.0, -172.0, -160.0, -160.0, -192.0, -146.0, -182.0, -180.0, -192.0, -194.0, -154.0, -180.0, -172.0, -168.0, -160.0, -176.0, -190.0, -176.0, -144.0, -190.0, -196.0, -176.0, -168.0, -196.0, -162.0, -174.0, -154.0, -190.0, -178.0, -166.0, -168.0, -190.0, -150.0, -186.0, -170.0, -194.0, -188.0, -142.0, -190.0, -170.0, -178.0, -162.0, -178.0, -190.0, -162.0, -168.0, -186.0, -180.0, -190.0, -166.0, -198.0, -194.0, -196.0, -190.0, -164.0, -184.0, -160.0, -178.0, -176.0, -148.0, -178.0, -182.0, -192.0, -188.0, -174.0, -176.0, -168.0, -166.0, -166.0, -190.0, -150.0, -128.0, -172.0, -158.0, -168.0, -174.0, -196.0, -190.0, -160.0, -176.0, -188.0, -164.0, -194.0, -188.0, -178.0, -164.0, -172.0, -160.0, -174.0, -176.0, -158.0, -182.0, -170.0, -180.0, -176.0, -164.0, -168.0, -188.0, -194.0, -176.0, -126.0, -178.0, -162.0, -172.0, -176.0, -194.0, -176.0, -188.0, -160.0, -174.0, -120.0, -190.0, -188.0, -136.0, -168.0, -190.0, -172.0, -186.0, -136.0, -162.0, -188.0, -168.0, -170.0, -198.0, -198.0, -192.0, -188.0, -164.0, -196.0, -156.0, -178.0, -192.0, -180.0, -186.0, -170.0, -172.0, -190.0, -158.0, -186.0, -182.0, -172.0, -158.0, -134.0, -172.0, -176.0, -184.0, -178.0, -146.0, -192.0, -184.0, -188.0, -168.0, -142.0, -190.0, -170.0, -190.0, -168.0, -188.0, -174.0, -188.0, -172.0, -198.0, -182.0, -154.0, -184.0, -196.0, -182.0, -194.0, -192.0, -150.0, -170.0, -144.0, -170.0, -186.0, -166.0, -184.0, -184.0, -186.0, -164.0, -180.0, -170.0, -174.0, -172.0, -184.0, -186.0, -168.0, -178.0, -178.0, -186.0, -170.0, -190.0, -174.0, -180.0, -152.0, -188.0, -186.0, -140.0, -186.0, -198.0, -164.0, -176.0, -178.0, -188.0, -176.0, -190.0, -198.0, -196.0, -132.0, -196.0, -188.0, -160.0, -176.0, -196.0, -194.0, -178.0, -158.0, -188.0, -180.0, -190.0, -172.0, -172.0, -174.0, -174.0, -164.0, -198.0, -170.0, -178.0, -178.0, -180.0, -194.0, -170.0, -188.0, -166.0, -186.0, -192.0, -184.0, -140.0, -186.0, -168.0, -166.0, -178.0, -176.0, -160.0, -182.0, -176.0, -182.0, -164.0, -172.0, -126.0, -184.0, -144.0, -178.0, -178.0, -128.0, -160.0, -160.0, -180.0, -186.0, -140.0, -174.0, -166.0, -168.0, -178.0, -172.0, -162.0, -172.0, -166.0, -192.0, -176.0, -166.0, -186.0, -180.0, -176.0, -166.0, -190.0, -184.0, -176.0, -198.0, -198.0, -178.0, -176.0, -194.0, -168.0, -188.0, -178.0, -168.0, -142.0, -174.0, -158.0, -178.0, -198.0, -174.0, -174.0, -172.0, -162.0, -194.0, -194.0, -158.0, -190.0, -196.0, -172.0, -160.0, -174.0, -168.0, -172.0, -196.0, -190.0, -168.0, -192.0, -164.0, -178.0, -188.0, -160.0, -174.0, -168.0, -192.0, -178.0, -124.0, -184.0, -132.0, -178.0, -196.0, -164.0, -182.0, -154.0, -186.0, -198.0, -160.0, -184.0, -172.0, -182.0, -174.0, -182.0, -186.0, -176.0, -162.0, -194.0, -168.0, -174.0, -186.0, -194.0, -176.0, -136.0, -186.0, -172.0, -180.0, -154.0, -196.0, -188.0, -180.0, -170.0, -184.0, -170.0, -194.0, -180.0, -194.0, -186.0, -180.0, -166.0, -178.0, -184.0, -178.0, -170.0, -180.0, -188.0, -166.0, -176.0, -174.0, -176.0, -166.0, -190.0, -180.0, -180.0, -190.0, -164.0, -166.0, -198.0, -138.0, -188.0, -132.0, -190.0, -182.0, -170.0, -180.0, -158.0, -180.0, -170.0, -182.0, -184.0, -170.0, -188.0, -180.0, -158.0, -166.0, -138.0, -152.0, -178.0, -162.0, -188.0, -158.0, -170.0, -170.0, -196.0, -172.0, -190.0, -172.0, -148.0, -190.0, -192.0, -168.0, -194.0, -168.0, -158.0, -122.0, -184.0, -178.0, -178.0, -150.0, -164.0, -190.0, -186.0, -198.0, -160.0, -176.0, -138.0]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "159996/159996 [==============================] - 13s 84us/step - loss: 0.1416\n",
      "Epoch 2/5\n",
      "159996/159996 [==============================] - 13s 81us/step - loss: 0.1415\n",
      "Epoch 3/5\n",
      "159996/159996 [==============================] - 14s 89us/step - loss: 0.1300\n",
      "Epoch 4/5\n",
      "159996/159996 [==============================] - 13s 83us/step - loss: 0.1107\n",
      "Epoch 5/5\n",
      "159996/159996 [==============================] - 13s 81us/step - loss: 0.1063\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -153., -149.,\n",
       "       -149., -147., -147., -145., -143., -143., -143., -141., -141.,\n",
       "       -140., -140., -140., -140., -140., -140., -138., -138., -138.,\n",
       "       -138., -137., -137., -137., -137., -137., -137., -136., -136.,\n",
       "       -136., -136., -136., -136., -136., -136., -136., -136., -136.,\n",
       "       -136., -136., -136., -135., -135., -135., -135., -135., -135.,\n",
       "       -135., -134., -134., -134., -134., -134., -134., -133., -132.,\n",
       "       -131., -131., -131., -131., -130., -130., -130., -130., -129.,\n",
       "       -129., -129., -129., -128., -128., -128., -128., -128., -128.,\n",
       "       -127., -126., -126., -126., -126., -126., -126., -126., -126.,\n",
       "       -126., -126., -126., -125., -125., -125., -125., -125., -125.,\n",
       "       -124.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mean_squared_logarithmic_error', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores3_order = np.sort(scores)\n",
    "avg_scores3 = sum(scores)/len(scores)\n",
    "scores3_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.1:  #self-defined\n",
    "                reward = 1.5\n",
    "            elif observation[0] > -0.2: # #self-defined\n",
    "                reward = 1\n",
    "            elif observation[0] > -0.3: # #self-defined\n",
    "                reward = 0.5\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-179.0, -191.0, -171.5, -182.0, -188.0, -168.5, -185.0, -182.0, -185.0, -186.5, -185.0, -182.0, -183.5, -189.5, -185.0, -192.5, -197.0, -183.5, -186.5, -160.0, -194.0, -176.0, -186.5, -186.5, -192.5, -186.5, -183.5, -186.5, -179.0, -183.5, -171.5, -186.5, -171.5, -182.0, -192.5, -147.5, -180.5, -186.5, -177.5, -156.5, -189.5, -189.5, -186.5, -179.0, -182.0, -183.5, -159.5, -188.0, -183.5, -195.5, -182.0, -194.0, -174.5, -160.5, -188.0, -180.5, -176.0, -185.0, -173.0, -182.0, -191.0, -192.5, -185.0, -189.5, -194.0, -180.5, -191.0, -197.0, -185.0, -194.0, -191.0, -189.5, -186.5, -185.0, -183.5, -173.0, -194.0, -173.0, -186.5, -176.0, -192.5, -170.0, -180.5, -173.0, -194.0, -174.5, -165.0, -177.5, -138.0, -192.5, -177.5, -174.5, -176.0, -173.0, -192.5, -191.0, -182.0, -179.0, -189.5, -167.0, -148.5, -153.5, -183.5, -182.0, -173.0, -174.5, -185.0, -185.0, -152.5, -182.0, -174.5, -183.5, -180.5, -194.0, -171.5, -177.5, -195.5, -195.5, -173.0, -183.5, -195.5, -164.0, -183.5, -182.0, -183.5, -185.0, -183.5, -185.0, -191.0, -192.5, -176.0, -141.0, -138.0, -192.5, -183.5, -176.0, -166.0, -188.0, -173.0, -183.5, -182.0, -195.5, -191.0, -195.5, -180.5, -189.5, -197.0, -195.5, -150.5, -182.0, -182.0, -162.5, -174.5, -192.5, -185.0, -186.5, -179.0, -174.5, -186.5, -183.5, -194.0, -185.0, -186.5, -168.5, -179.0, -195.5, -195.5, -192.5, -167.0, -192.5, -168.5, -183.5, -180.5, -183.5, -183.5, -150.5, -195.5, -182.0, -173.0, -174.5, -180.5, -188.0, -164.5, -195.5, -189.5, -156.5, -189.5, -192.5, -191.0, -182.0, -188.0, -194.0, -194.0, -182.0, -176.0, -168.5, -145.0, -189.5, -188.0, -188.0, -179.0, -174.5, -188.0, -182.0, -171.5, -176.0, -185.0, -192.5, -182.0, -192.5, -191.0, -183.5, -173.0, -185.0, -162.5, -179.0, -186.5, -180.5, -186.5, -188.0, -182.0, -191.0, -179.0, -179.0, -188.0, -177.5, -191.0, -197.0, -176.0, -182.0, -174.5, -179.0, -186.5, -185.0, -182.0, -174.5, -179.0, -171.5, -186.5, -188.0, -174.5, -182.0, -179.0, -195.5, -183.5, -185.0, -188.0, -180.5, -173.0, -123.5, -171.5, -174.5, -188.0, -192.5, -176.0, -179.0, -125.5, -185.0, -183.5, -179.0, -185.0, -186.5, -180.5, -188.0, -174.5, -189.5, -188.0, -191.0, -191.0, -186.5, -195.5, -177.5, -185.0, -189.5, -164.0, -170.0, -177.5, -191.0, -192.5, -183.5, -185.0, -161.0, -185.0, -168.5, -180.5, -145.0, -177.5, -174.5, -183.5, -180.5, -194.0, -191.0, -186.5, -180.5, -189.5, -183.5, -191.0, -195.5, -182.0, -180.5, -194.0, -162.5, -177.5, -177.5, -182.0, -182.0, -189.5, -179.0, -135.5, -185.0, -174.5, -189.5, -183.5, -182.0, -161.0, -174.5, -177.5, -182.0, -186.5, -192.5, -182.0, -180.5, -197.0, -174.5, -185.0, -162.5, -191.0, -185.0, -183.5, -155.0, -185.0, -171.5, -182.0, -186.5, -183.5, -197.0, -177.5, -185.0, -197.0, -170.0, -179.0, -176.0, -183.5, -162.0, -166.0, -182.0, -177.5, -186.5, -155.0, -191.0, -179.0, -194.0, -195.5, -162.5, -194.0, -174.5, -186.5, -194.0, -174.5, -171.5, -183.5, -169.5, -183.5, -192.5, -194.0, -186.5, -177.5, -189.5, -182.0, -182.0, -174.5, -197.0, -195.5, -179.0, -192.5, -192.5, -174.5, -167.0, -177.5, -182.0, -180.5, -186.5, -194.0, -171.5, -176.0, -183.5, -186.5, -186.5, -186.5, -177.5, -159.5, -171.5, -177.5, -164.0, -171.5, -182.0, -144.0, -173.0, -179.0, -189.5, -183.5, -182.0, -189.5, -176.0, -179.0, -182.0, -195.5, -188.0, -170.0, -177.5, -182.0, -180.5, -191.0, -185.0, -147.5, -180.5, -191.0, -182.0, -180.5, -173.0, -194.0, -176.0, -195.5, -158.0, -182.0, -182.0, -179.0, -197.0, -191.0, -194.0, -171.5, -162.5, -183.5, -177.5, -176.0, -186.5, -189.5, -183.5, -173.0, -179.0, -182.0, -195.5, -162.5, -180.5, -179.0, -164.0, -174.5, -186.5, -194.0, -191.0, -183.5, -180.5, -188.0, -186.5, -191.0, -194.0, -185.0, -154.5, -183.5, -179.0, -191.0, -185.0, -189.5, -191.0, -165.5, -171.5, -191.0, -164.0, -188.0, -180.5, -186.5, -180.5, -188.0, -195.5, -189.5, -192.5, -182.0, -186.5, -180.5, -183.5, -179.0, -174.5, -179.0, -161.0, -197.0, -170.0, -174.5, -186.5, -195.5, -173.0, -144.5, -197.0, -194.0, -176.0, -153.5, -158.5, -153.0, -176.0, -186.5, -179.0, -176.0, -182.0, -173.0, -171.5, -195.5, -177.5, -188.0, -147.0, -179.0, -183.5, -182.0, -149.5, -195.5, -186.5, -177.5, -179.0, -195.5, -189.5, -179.0, -177.5, -197.0, -191.0, -191.0, -192.5, -183.5, -181.5, -176.0, -194.0, -179.0, -194.0, -185.0, -194.0, -179.0, -182.0, -183.5, -189.5, -191.0, -179.0, -132.5, -176.0, -183.5, -189.5, -183.5, -180.5, -191.0, -195.5, -167.0, -191.0, -176.0, -186.5, -182.0, -153.5, -182.0, -170.0, -173.0, -182.0, -182.0, -176.0, -192.5, -186.5, -189.5, -183.5, -176.0, -180.5, -174.5, -191.0, -192.5, -194.0, -183.5, -186.5, -189.5, -177.5, -195.5, -183.5, -180.5, -189.5, -185.0, -188.0, -156.5, -189.5, -182.0, -183.5, -153.5, -155.0, -185.0, -189.5, -156.5, -174.5, -188.0, -180.5, -188.0, -174.5, -125.5, -182.0, -156.5, -168.5, -189.5, -179.0, -174.5, -185.0, -141.5, -171.5, -149.0, -143.5, -180.5, -173.0, -182.0, -191.0, -185.0, -182.0, -179.0, -191.0, -183.5, -128.0, -188.0, -180.5, -168.0, -183.5, -189.5, -182.0, -166.5, -164.0, -183.5, -188.0, -189.5, -177.5, -179.0, -185.0, -192.5, -180.5, -189.5, -156.5, -191.0, -174.5, -174.5, -188.0, -189.5, -188.0, -194.0, -151.0, -177.5, -194.0, -192.5, -177.5, -194.0, -177.5, -152.0, -167.0, -180.5, -161.0, -180.5, -186.5, -171.5, -153.5, -179.0, -164.0, -173.0, -168.5, -171.5, -192.5, -164.0, -170.0, -197.0, -185.0, -185.0, -175.5, -189.5, -194.0, -183.5, -186.5, -180.5, -182.0, -182.0, -159.0, -177.5, -176.0, -177.5, -158.0, -197.0, -179.0, -179.0, -177.5, -158.5, -192.5, -188.0, -183.5, -182.0, -152.0, -139.0, -183.5, -133.5, -177.5, -165.5, -179.0, -195.5, -167.0, -192.5, -183.5, -176.0, -174.5, -197.0, -171.5, -197.0, -173.0, -170.5, -177.5, -156.5, -197.0, -191.0, -150.5, -188.0, -176.0, -182.0, -189.5, -191.0, -171.5, -179.0, -149.0, -168.5, -192.5, -185.0, -191.0, -177.5, -174.5, -186.5, -191.0, -182.0, -179.0, -170.0, -159.5, -180.5, -170.0, -177.5, -191.0, -182.0, -185.0, -177.5, -179.0, -177.5, -164.0, -149.0, -191.0, -195.5, -183.5, -173.0, -195.5, -189.5]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "148653/148653 [==============================] - 12s 80us/step - loss: 0.1053\n",
      "Epoch 2/5\n",
      "148653/148653 [==============================] - 12s 80us/step - loss: 0.1048\n",
      "Epoch 3/5\n",
      "148653/148653 [==============================] - 13s 84us/step - loss: 0.1047\n",
      "Epoch 4/5\n",
      "148653/148653 [==============================] - 13s 86us/step - loss: 0.1047\n",
      "Epoch 5/5\n",
      "148653/148653 [==============================] - 13s 89us/step - loss: 0.1046\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -157.,\n",
       "       -157., -157., -156., -156., -156., -125., -124., -121., -119.,\n",
       "       -118., -118., -117., -117., -117., -117., -117., -117., -117.,\n",
       "       -117., -117., -117., -117., -117., -117., -116., -116., -116.,\n",
       "       -116., -116., -116., -116., -116., -116., -116., -116., -116.,\n",
       "       -116., -116., -116., -116., -116., -116., -115., -115., -115.,\n",
       "       -115., -115., -115., -115., -115., -115., -115., -115., -115.,\n",
       "       -115., -115., -114., -114., -114., -114., -114., -114., -114.,\n",
       "       -114., -114., -114., -114., -114., -114., -114., -114., -114.,\n",
       "       -114., -114., -113., -113., -113., -113., -113., -113., -113.,\n",
       "       -113.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='logcosh', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores4_order = np.sort(scores)\n",
    "avg_scores4 = sum(scores)/len(scores)\n",
    "scores4_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.1:  #self-defined\n",
    "                reward = 9\n",
    "            elif observation[0] > -0.2: # #self-defined\n",
    "                reward = 0.6\n",
    "            elif observation[0] > -0.3: # #self-defined\n",
    "                reward = 0.3\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-194.8, -184.39999999999986, -196.09999999999997, -180.49999999999983, -179.19999999999982, -189.5999999999999, -188.3, -154.29999999999987, -192.19999999999993, -194.79999999999995, -150.0999999999999, -159.70000000000007, -190.89999999999992, -190.90000000000003, -197.39999999999998, -189.5999999999999, -194.79999999999995, -185.70000000000005, -181.79999999999984, -197.39999999999998, -157.09999999999985, -171.40000000000006, -183.10000000000002, -176.59999999999985, -193.49999999999994, -193.49999999999994, -186.9999999999999, -197.39999999999998, -190.90000000000003, -176.59999999999985, -187.00000000000003, -190.89999999999998, -179.19999999999982, -185.69999999999987, -172.50000000000006, -172.6999999999998, -186.9999999999999, -181.79999999999984, -196.09999999999997, -184.39999999999986, -192.20000000000002, -189.5999999999999, -194.8, -167.39999999999998, -194.79999999999995, -185.69999999999987, -181.7999999999999, -196.09999999999997, -189.5999999999999, -189.5999999999999, -188.2999999999999, -197.39999999999998, -181.79999999999984, -196.09999999999997, -194.79999999999995, -194.79999999999995, -186.9999999999999, -192.19999999999993, -188.2999999999999, -164.5, -185.69999999999987, -155.80000000000007, -188.2999999999999, -180.49999999999983, -175.29999999999978, -193.49999999999994, -186.9999999999999, -185.69999999999987, -188.2999999999999, -180.49999999999983, -179.19999999999982, -189.5999999999999, -184.39999999999986, -189.5999999999999, -180.49999999999983, -190.89999999999992, -180.49999999999983, -193.49999999999994, -181.79999999999984, -154.49999999999986, -173.99999999999977, -186.9999999999999, -190.89999999999992, -158.4000000000001, -189.5999999999999, -196.09999999999997, -179.19999999999982, -190.89999999999998, -185.69999999999987, -193.49999999999994, -196.09999999999997, -186.9999999999999, -189.5999999999999, -179.19999999999987, -171.3999999999998, -184.39999999999986, -190.89999999999992, -186.9999999999999, -194.8, -188.2999999999999, -175.29999999999978, -189.29999999999993, -188.2999999999999, -175.3, -189.5999999999999, -179.19999999999982, -176.5999999999998, -196.09999999999997, -166.20000000000007, -189.5999999999999, -184.39999999999986, -190.89999999999992, -180.49999999999986, -185.70000000000005, -181.79999999999984, -180.49999999999983, -164.89999999999984, -194.79999999999995, -181.80000000000004, -192.19999999999993, -196.09999999999997, -176.60000000000005, -167.50000000000006, -184.39999999999986, -184.39999999999986, -183.09999999999985, -184.39999999999986, -176.5999999999998, -196.09999999999997, -185.69999999999987, -154.59999999999988, -173.09999999999982, -181.79999999999984, -180.49999999999991, -184.39999999999986, -194.79999999999995, -183.0999999999999, -189.5999999999999, -194.79999999999995, -162.29999999999978, -166.19999999999982, -188.2999999999999, -183.09999999999985, -188.29999999999995, -180.49999999999983, -180.49999999999983, -184.39999999999986, -193.49999999999994, -193.49999999999994, -185.69999999999987, -188.2999999999999, -185.69999999999987, -188.2999999999999, -186.9999999999999, -167.50000000000006, -180.49999999999983, -193.49999999999994, -179.19999999999993, -177.89999999999998, -186.9999999999999, -176.5999999999998, -179.19999999999982, -86.40000000000009, -180.49999999999983, -173.99999999999977, -183.10000000000002, -188.2999999999999, -189.5999999999999, -190.89999999999992, -181.79999999999984, -192.19999999999993, -181.79999999999984, -194.79999999999995, -179.19999999999982, -164.9000000000001, -175.29999999999978, -177.8999999999998, -192.19999999999993, -183.09999999999985, -193.49999999999994, -184.39999999999986, -181.79999999999984, -192.19999999999993, -189.5999999999999, -186.9999999999999, -189.5999999999999, -159.30000000000013, -192.19999999999993, -189.5999999999999, -197.39999999999998, -197.39999999999998, -177.8999999999998, -190.89999999999992, -183.09999999999985, -197.39999999999998, -189.5999999999999, -190.89999999999992, -167.4999999999999, -184.39999999999986, -177.8999999999998, -180.49999999999983, -188.3, -180.49999999999983, -192.19999999999993, -150.00000000000014, -159.69999999999982, -183.09999999999985, -164.89999999999986, -188.2999999999999, -176.5999999999998, -190.89999999999992, -185.7, -179.19999999999982, -177.8999999999998, -179.19999999999982, -168.79999999999984, -183.09999999999985, -185.69999999999987, -197.39999999999998, -193.49999999999994, -181.79999999999984, -180.49999999999983, -177.8999999999998, -186.9999999999999, -189.5999999999999, -179.19999999999982, -184.39999999999986, -193.49999999999994, -184.39999999999986, -186.9999999999999, -188.3, -184.39999999999992, -172.69999999999976, -190.89999999999992, -193.49999999999994, -186.9999999999999, -184.39999999999986, -183.09999999999985, -185.69999999999987, -184.39999999999986, -184.39999999999986, -186.9999999999999, -190.90000000000003, -183.09999999999994, -188.2999999999999, -186.9999999999999, -177.8999999999998, -189.5999999999999, -184.40000000000003, -176.5999999999998, -186.9999999999999, -184.39999999999986, -177.8999999999998, -184.39999999999986, -194.79999999999995, -190.89999999999992, -189.5999999999999, -179.19999999999982, -181.79999999999984, -196.09999999999997, -184.39999999999986, -185.69999999999987, -179.20000000000005, -172.69999999999976, -193.49999999999994, -192.19999999999993, -159.5000000000001, -192.19999999999993, -173.99999999999977, -188.2999999999999, -196.10000000000002, -184.39999999999986, -177.90000000000003, -189.5999999999999, -189.5999999999999, -197.4, -184.39999999999992, -192.19999999999993, -193.5, -190.89999999999992, -175.29999999999978, -190.90000000000003, -186.9999999999999, -162.29999999999993, -194.8, -184.39999999999986, -184.40000000000003, -147.29999999999998, -194.79999999999995, -190.89999999999992, -197.39999999999998, -176.5999999999998, -190.90000000000003, -192.19999999999993, -171.3999999999998, -170.09999999999985, -192.19999999999993, -183.09999999999985, -185.69999999999987, -173.9999999999999, -184.40000000000003, -196.10000000000002, -158.4000000000001, -183.09999999999985, -185.69999999999987, -189.5999999999999, -190.89999999999992, -192.20000000000002, -180.49999999999983, -179.19999999999987, -181.79999999999984, -183.10000000000002, -170.89999999999998, -193.49999999999994, -184.40000000000003, -184.39999999999986, -176.5999999999998, -192.19999999999993, -184.39999999999986, -171.90000000000003, -184.39999999999986, -157.10000000000008, -184.39999999999986, -189.5999999999999, -181.79999999999984, -162.30000000000007, -181.79999999999984, -179.19999999999982, -190.89999999999992, -190.89999999999992, -185.70000000000005, -145.80000000000007, -190.89999999999992, -194.79999999999995, -186.9999999999999, -192.20000000000002, -179.19999999999982, -184.39999999999986, -196.09999999999997, -186.9999999999999, -180.49999999999983, -186.9999999999999, -189.5999999999999, -186.9999999999999, -148.00000000000014, -188.2999999999999, -190.90000000000003, -189.5999999999999, -192.19999999999993, -183.09999999999985, -197.4, -190.89999999999992, -160.99999999999983, -188.2999999999999, -167.49999999999986, -196.09999999999997, -196.10000000000002, -180.49999999999983, -177.8999999999998, -193.49999999999994, -175.29999999999984, -186.9999999999999, -181.79999999999984, -180.49999999999986, -165.6, -183.0999999999999, -186.9999999999999, -194.79999999999995, -180.49999999999983, -188.2999999999999, -197.39999999999998, -176.5999999999998, -167.49999999999986, -164.89999999999978, -186.9999999999999, -188.29999999999995, -167.49999999999991, -186.9999999999999, -179.19999999999982, -190.89999999999992, -181.80000000000004, -197.39999999999998, -181.79999999999984, -180.49999999999983, -194.79999999999995, -192.19999999999993, -188.2999999999999, -180.49999999999983, -184.39999999999986, -192.2, -176.5999999999998, -188.2999999999999, -153.60000000000002, -180.49999999999983, -179.19999999999982, -181.79999999999984, -184.39999999999986, -177.8999999999998, -192.20000000000002, -175.29999999999978, -190.89999999999992, -183.09999999999985, -181.80000000000004, -177.90000000000003, -181.79999999999984, -190.89999999999992, -184.39999999999992, -190.89999999999992, -190.89999999999992, -186.9999999999999, -185.69999999999987, -184.39999999999986, -177.8999999999998, -194.79999999999995, -188.2999999999999, -185.70000000000005, -194.79999999999995, -186.9999999999999, -188.2999999999999, -185.69999999999987, -192.19999999999993, -177.8999999999998, -183.09999999999997, -183.09999999999985, -196.09999999999997, -185.69999999999987, -190.89999999999992, -177.8999999999998, -167.49999999999994, -190.89999999999992, -181.8, -190.89999999999992, -161.1, -167.0999999999999, -179.19999999999982, -186.9999999999999, -171.39999999999975, -185.69999999999987, -173.99999999999977, -193.49999999999994, -197.39999999999998, -181.79999999999984, -186.9999999999999, -181.80000000000004, -173.99999999999977, -183.09999999999985, -153.8, -170.90000000000003, -189.5999999999999, -192.19999999999993, -194.79999999999995, -197.4, -181.79999999999984, -194.79999999999995, -185.69999999999987, -184.39999999999986, -170.09999999999985, -196.09999999999997, -183.09999999999985, -184.39999999999986, -184.39999999999986, -185.69999999999987, -185.69999999999987, -186.9999999999999, -181.79999999999984, -190.89999999999992, -190.89999999999992, -181.79999999999995, -176.5999999999998, -194.79999999999995, -184.39999999999986, -188.2999999999999, -187.0, -193.49999999999994, -175.30000000000007, -176.5999999999998, -194.79999999999995, -192.19999999999993, -185.69999999999987, -166.19999999999993, -188.2999999999999, -180.49999999999983, -190.89999999999992, -186.9999999999999, -196.09999999999997, -172.69999999999982, -192.19999999999993, -183.09999999999985, -188.2999999999999, -144.70000000000016, -186.9999999999999, -181.79999999999984, -176.60000000000005, -181.79999999999984, -162.30000000000013, -180.49999999999983, -189.5999999999999, -183.09999999999985, -192.19999999999993, -177.8999999999998, -161.00000000000009, -179.1999999999999, -197.39999999999998, -177.8999999999998, -190.89999999999992, -181.79999999999984, -184.39999999999986, -168.7999999999999, -192.19999999999993, -168.89999999999992, -197.39999999999998, -194.79999999999995, -177.89999999999992, -167.79999999999995, -179.19999999999982, -186.9999999999999, -177.90000000000003, -183.09999999999985, -151.60000000000008, -171.40000000000006, -173.99999999999994, -176.5999999999998, -172.19999999999987, -185.69999999999987, -189.5999999999999, -189.5999999999999, -186.9999999999999, -185.70000000000005, -180.49999999999983, -186.9999999999999, -194.79999999999995, -194.79999999999995, -177.8999999999998, -194.8, -173.99999999999991, -193.49999999999994, -162.30000000000007, -176.5999999999998, -193.49999999999994, -188.2999999999999, -183.09999999999985, -186.9999999999999, -189.5999999999999, -183.10000000000002, -171.39999999999992, -181.79999999999984, -184.39999999999986, -180.49999999999983, -184.39999999999986, -153.2000000000001, -194.79999999999995, -183.09999999999985, -189.60000000000002, -185.69999999999987, -186.39999999999992, -166.79999999999993, -188.2999999999999, -189.5999999999999, -183.09999999999985, -190.89999999999992, -183.09999999999985, -180.49999999999983, -189.5999999999999, -176.5999999999998, -192.19999999999993, -181.79999999999995, -181.79999999999984, -186.9999999999999, -183.09999999999985, -190.89999999999998, -192.19999999999993, -184.39999999999986, -194.79999999999995, -183.09999999999985, -181.79999999999984, -196.09999999999997, -185.69999999999987, -189.59999999999994, -190.89999999999992, -193.49999999999994, -184.39999999999986, -183.09999999999985, -193.49999999999994, -190.89999999999992, -188.2999999999999, -166.79999999999993, -176.5999999999998, -196.09999999999997, -197.39999999999998, -181.79999999999984, -179.19999999999982, -186.9999999999999, -194.79999999999995, -188.2999999999999, -175.79999999999993, -189.5999999999999, -177.8999999999998, -197.39999999999998, -190.89999999999992, -175.29999999999978, -193.49999999999994, -183.09999999999985, -192.19999999999993, -194.8, -188.2999999999999, -181.79999999999984, -189.5999999999999, -196.10000000000002, -188.2999999999999, -173.99999999999977, -177.8999999999998, -193.49999999999994, -167.4999999999999, -183.09999999999985, -171.19999999999985, -181.79999999999984, -154.09999999999997, -189.5999999999999, -192.19999999999993, -192.19999999999993, -189.5999999999999, -177.8999999999998, -179.19999999999982, -192.19999999999993, -176.5999999999998, -189.5999999999999, -186.9999999999999, -194.79999999999995, -188.2999999999999, -180.49999999999983, -188.2999999999999, -189.5999999999999, -171.40000000000006, -181.79999999999984, -184.39999999999986, -180.49999999999983, -188.2999999999999, -193.49999999999994, -180.49999999999983, -183.0999999999999, -183.09999999999985, -189.5999999999999, -175.29999999999978, -167.8000000000001, -166.20000000000007, -196.09999999999997, -192.19999999999993, -193.49999999999994, -194.79999999999995, -179.19999999999982, -170.4999999999998, -181.79999999999984, -183.10000000000002, -162.29999999999984, -194.79999999999995, -177.8999999999998, -181.79999999999984, -192.19999999999993, -168.80000000000007, -197.39999999999998, -190.89999999999992, -186.9999999999999, -194.79999999999995, -181.79999999999995, -175.29999999999978, -192.19999999999993, -179.19999999999982, -189.5999999999999, -184.39999999999986, -194.79999999999995, -174.7999999999999, -176.5999999999998, -177.90000000000003, -171.3999999999999, -186.9999999999999, -183.09999999999985, -192.19999999999993, -170.19999999999982, -189.5999999999999, -171.19999999999985, -185.69999999999987, -183.09999999999985, -181.80000000000004, -185.70000000000005, -185.69999999999987, -176.5999999999998, -158.4000000000001, -181.79999999999984, -186.9999999999999, -179.19999999999982, -173.9999999999999, -192.19999999999993, -197.39999999999998, -190.89999999999992, -181.79999999999984, -175.29999999999978, -189.5999999999999, -172.69999999999976, -196.09999999999997, -180.49999999999983, -146.20000000000013, -196.09999999999997, -183.09999999999985, -175.29999999999978, -183.09999999999985, -186.9999999999999, -184.39999999999986, -183.09999999999985, -181.79999999999984, -180.49999999999983, -186.9999999999999, -184.39999999999986, -169.29999999999993, -183.09999999999985, -170.59999999999988, -180.49999999999983, -196.09999999999997, -184.39999999999986, -184.40000000000003, -185.69999999999987, -172.69999999999982, -194.79999999999995, -192.19999999999993, -192.19999999999993, -175.2999999999999, -177.89999999999992, -184.39999999999992, -176.5999999999998, -171.4, -185.6999999999999, -189.5999999999999, -159.0, -186.9999999999999, -180.49999999999983, -170.09999999999997, -179.19999999999982, -174.00000000000006, -179.19999999999982, -171.40000000000006, -186.9999999999999, -170.09999999999985, -189.5999999999999, -188.2999999999999, -185.69999999999987, -181.79999999999984, -190.89999999999992, -183.09999999999985, -190.89999999999992, -186.9999999999999, -186.9999999999999, -196.09999999999997, -183.09999999999985, -183.09999999999985, -189.5999999999999, -193.49999999999994, -194.79999999999995, -166.19999999999993, -173.99999999999977, -169.59999999999985, -183.09999999999985, -185.6999999999999, -184.39999999999986, -186.9999999999999, -188.2999999999999, -197.39999999999998, -189.5999999999999, -183.09999999999985, -188.2999999999999, -181.79999999999984, -179.19999999999982, -175.29999999999987, -176.5999999999998, -176.5999999999998, -179.20000000000005, -192.19999999999993, -185.69999999999987, -186.99999999999994, -179.19999999999982, -194.79999999999995, -183.09999999999985, -181.79999999999984, -150.7000000000001, -187.00000000000003, -185.69999999999987, -155.7999999999999, -181.79999999999984, -184.39999999999986, -196.10000000000002, -196.09999999999997, -193.49999999999994, -196.09999999999997, -164.9000000000001, -186.9999999999999, -186.9999999999999, -197.39999999999998, -184.40000000000003, -194.79999999999995, -192.19999999999993, -194.79999999999995, -185.69999999999987, -186.9999999999999, -192.19999999999993, -188.2999999999999, -196.09999999999997, -181.79999999999984, -192.19999999999993, -183.09999999999985, -183.09999999999985, -167.50000000000006]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160991/160991 [==============================] - 14s 88us/step - loss: 0.8873\n",
      "Epoch 2/5\n",
      "160991/160991 [==============================] - 14s 89us/step - loss: 0.8850\n",
      "Epoch 3/5\n",
      "160991/160991 [==============================] - 15s 91us/step - loss: 0.8843\n",
      "Epoch 4/5\n",
      "160991/160991 [==============================] - 16s 99us/step - loss: 0.8837\n",
      "Epoch 5/5\n",
      "160991/160991 [==============================] - 15s 92us/step - loss: 0.8834\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-146., -145., -143., -138., -138., -136., -135., -132., -130.,\n",
       "       -130., -128., -127., -127., -127., -127., -127., -127., -127.,\n",
       "       -127., -127., -127., -127., -127., -127., -127., -127., -127.,\n",
       "       -127., -127., -127., -127., -127., -127., -127., -127., -127.,\n",
       "       -127., -127., -127., -127., -126., -126., -126., -126., -126.,\n",
       "       -126., -126., -126., -126., -126., -126., -126., -126., -126.,\n",
       "       -126., -126., -126., -126., -126., -126., -126., -126., -126.,\n",
       "       -126., -126., -126., -126., -125., -125., -125., -125., -125.,\n",
       "       -125., -125., -125., -125., -125., -125., -125., -125., -125.,\n",
       "       -125., -125., -125., -124., -124., -121., -108.,  -99.,  -98.,\n",
       "        -97.,  -96.,  -95.,  -94.,  -91.,  -91.,  -90.,  -87.,  -87.,\n",
       "        -86.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='squared_hinge', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores5_order = np.sort(scores)\n",
    "avg_scores5 = sum(scores)/len(scores)\n",
    "scores5_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.1:  #self-defined\n",
    "                reward = 9\n",
    "            elif observation[0] > -0.2: # #self-defined\n",
    "                reward = 0.6\n",
    "            elif observation[0] > -0.3: # #self-defined\n",
    "                reward = 0.3\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-193.49999999999994, -149.2999999999998, -172.6999999999999, -183.09999999999985, -183.09999999999985, -197.39999999999998, -188.2999999999999, -197.4, -180.49999999999983, -188.29999999999995, -188.2999999999999, -197.39999999999998, -167.50000000000006, -197.4, -193.49999999999994, -197.39999999999998, -167.49999999999986, -184.39999999999986, -176.5999999999999, -196.09999999999997, -181.79999999999984, -175.29999999999978, -179.19999999999982, -192.19999999999993, -184.39999999999986, -185.7, -190.89999999999992, -185.69999999999987, -171.39999999999998, -185.69999999999987, -171.39999999999986, -158.4000000000001, -186.9999999999999, -183.09999999999985, -184.39999999999986, -186.9999999999999, -179.19999999999982, -197.39999999999998, -186.9999999999999, -190.89999999999992, -197.39999999999998, -194.79999999999995, -194.79999999999995, -193.49999999999994, -184.40000000000003, -184.40000000000003, -189.5999999999999, -192.19999999999993, -196.09999999999997, -177.8999999999998, -194.79999999999995, -164.89999999999986, -179.19999999999982, -193.49999999999994, -192.19999999999993, -179.19999999999996, -197.39999999999998, -181.79999999999984, -177.8999999999998, -184.39999999999986, -180.49999999999983, -176.5999999999998, -183.10000000000002, -189.5999999999999, -194.79999999999995, -175.29999999999978, -177.89999999999986, -184.39999999999995, -192.2, -194.79999999999995, -184.39999999999986, -194.79999999999995, -163.60000000000008, -184.39999999999986, -197.39999999999998, -189.5999999999999, -192.19999999999993, -193.5, -185.69999999999987, -189.5999999999999, -179.19999999999982, -192.19999999999993, -192.19999999999993, -189.5999999999999, -185.79999999999995, -189.5999999999999, -181.79999999999984, -190.90000000000003, -185.69999999999987, -166.29999999999984, -185.69999999999987, -180.49999999999983, -185.69999999999987, -181.79999999999984, -180.49999999999983, -183.09999999999985, -180.49999999999983, -183.09999999999985, -197.39999999999998, -181.80000000000004, -176.5999999999998, -186.9999999999999, -180.49999999999986, -193.5, -184.39999999999986, -196.09999999999997, -193.5, -181.79999999999984, -186.9999999999999, -197.39999999999998, -186.9999999999999, -186.9999999999999, -188.2999999999999, -171.3999999999999, -190.90000000000003, -193.49999999999994, -167.39999999999998, -192.19999999999993, -177.89999999999992, -163.29999999999995, -164.9000000000001, -171.5999999999999, -154.4, -188.2999999999999, -185.69999999999987, -192.19999999999993, -194.79999999999995, -194.8, -183.09999999999985, -184.40000000000003, -189.60000000000002, -189.5999999999999, -184.39999999999986, -188.2999999999999, -175.29999999999978, -192.19999999999993, -189.6, -196.09999999999997, -170.59999999999988, -186.9999999999999, -186.9999999999999, -167.5, -185.69999999999987, -189.5999999999999, -181.79999999999984, -177.8999999999998, -194.79999999999995, -192.19999999999993, -183.09999999999985, -190.89999999999992, -186.9999999999999, -180.49999999999983, -189.5999999999999, -189.5999999999999, -185.69999999999987, -173.99999999999977, -180.50000000000006, -180.50000000000006, -186.9999999999999, -184.39999999999986, -188.2999999999999, -172.0999999999998, -197.39999999999998, -177.89999999999992, -184.39999999999986, -183.09999999999985, -177.8999999999998, -185.69999999999987, -190.89999999999992, -181.79999999999984, -181.79999999999984, -184.39999999999986, -194.79999999999995, -186.9999999999999, -192.19999999999993, -179.19999999999982, -177.89999999999992, -197.39999999999998, -193.49999999999994, -192.19999999999993, -194.79999999999995, -193.49999999999994, -186.9999999999999, -196.09999999999997, -181.79999999999984, -184.39999999999986, -157.10000000000008, -185.69999999999987, -180.49999999999983, -180.49999999999983, -181.79999999999984, -180.49999999999983, -177.8999999999998, -175.29999999999978, -176.5999999999998, -190.89999999999992, -185.69999999999987, -193.49999999999994, -179.19999999999982, -188.2999999999999, -179.19999999999982, -192.19999999999993, -160.80000000000007, -190.89999999999992, -179.19999999999982, -190.89999999999992, -161.30000000000013, -172.69999999999976, -192.19999999999993, -160.99999999999991, -189.5999999999999, -159.7000000000001, -164.59999999999997, -196.09999999999997, -179.19999999999982, -196.09999999999997, -181.79999999999984, -184.39999999999986, -186.9999999999999, -179.20000000000005, -184.39999999999986, -175.29999999999978, -167.50000000000003, -181.79999999999984, -193.49999999999994, -186.9999999999999, -180.49999999999983, -193.5, -154.5000000000001, -185.69999999999987, -192.19999999999993, -176.5999999999998, -183.09999999999985, -192.19999999999993, -181.79999999999998, -183.09999999999985, -184.39999999999986, -190.89999999999992, -181.79999999999984, -192.20000000000002, -192.20000000000002, -197.39999999999998, -193.49999999999994, -184.40000000000003, -170.4999999999999, -188.3, -173.99999999999977, -193.49999999999994, -175.29999999999978, -184.39999999999986, -189.5999999999999, -162.29999999999984, -186.9999999999999, -183.09999999999985, -154.40000000000012, -184.39999999999986, -180.49999999999983, -184.39999999999995, -171.39999999999984, -192.20000000000002, -190.89999999999992, -188.2999999999999, -194.79999999999995, -190.89999999999992, -185.69999999999987, -181.79999999999984, -186.9999999999999, -186.9999999999999, -170.2999999999999, -192.19999999999993, -186.9999999999999, -189.5999999999999, -188.2999999999999, -189.5999999999999, -197.39999999999998, -186.9999999999999, -177.8999999999998, -171.39999999999986, -194.79999999999995, -189.5999999999999, -184.39999999999986, -172.6999999999999, -180.49999999999986, -172.7, -179.19999999999982, -177.90000000000003, -184.39999999999986, -183.10000000000002, -185.69999999999987, -173.99999999999977, -184.39999999999986, -186.9999999999999, -192.20000000000002, -190.89999999999992, -180.49999999999983, -180.50000000000006, -188.2999999999999, -176.59999999999982, -184.39999999999986, -175.3, -196.09999999999997, -186.9999999999999, -192.19999999999993, -184.39999999999986, -181.79999999999984, -194.79999999999995, -185.69999999999987, -184.39999999999986, -194.79999999999995, -184.39999999999986, -188.2999999999999, -194.8, -192.19999999999993, -184.39999999999986, -175.29999999999978, -185.69999999999987, -192.19999999999993, -181.79999999999984, -193.49999999999994, -180.49999999999983, -193.49999999999994, -179.19999999999982, -183.10000000000002, -190.89999999999992, -180.49999999999983, -193.49999999999994, -180.49999999999983, -185.69999999999987, -192.19999999999993, -189.5999999999999, -176.5999999999998, -177.8999999999998, -162.30000000000007, -183.09999999999985, -193.49999999999994, -192.19999999999993, -194.79999999999995, -190.89999999999992, -183.09999999999985, -159.7000000000001, -192.19999999999993, -188.2999999999999, -175.2999999999999, -196.09999999999997, -183.09999999999985, -173.3999999999998, -181.79999999999984, -173.3999999999998, -186.99999999999994, -188.2999999999999, -188.2999999999999, -155.8000000000001, -190.89999999999998, -186.9999999999999, -193.49999999999994, -177.8999999999998, -181.79999999999984, -193.49999999999994, -188.2999999999999, -190.90000000000003, -194.79999999999995, -180.49999999999983, -184.39999999999986, -162.29999999999978, -161.00000000000009, -181.79999999999984, -176.5999999999998, -187.00000000000003, -168.29999999999984, -180.49999999999986, -176.5999999999998, -177.8999999999998, -194.79999999999995, -181.79999999999984, -183.09999999999985, -177.8999999999998, -184.39999999999986, -171.40000000000006, -179.19999999999982, -184.39999999999986, -184.39999999999986, -186.99999999999994, -181.79999999999984, -180.49999999999983, -186.9999999999999, -183.09999999999985, -194.79999999999995, -179.19999999999982, -184.39999999999986, -183.09999999999985, -177.8999999999998, -176.5999999999998, -185.69999999999987, -190.89999999999992, -197.4, -192.19999999999993, -167.50000000000006, -193.49999999999994, -180.49999999999983, -175.29999999999978, -177.8999999999998, -167.49999999999983, -186.9999999999999, -196.09999999999997, -181.79999999999984, -179.19999999999982, -197.39999999999998, -184.40000000000003, -179.19999999999996, -192.20000000000002, -192.19999999999993, -197.39999999999998, -177.90000000000003, -153.60000000000008, -196.09999999999997, -188.2999999999999, -192.19999999999993, -181.79999999999984, -158.4000000000001, -149.30000000000013, -185.69999999999987, -196.09999999999997, -196.09999999999997, -189.5999999999999, -185.69999999999987, -168.80000000000007, -194.79999999999995, -171.19999999999985, -192.20000000000002, -181.80000000000004, -179.19999999999993, -186.9999999999999, -186.9999999999999, -189.5999999999999, -188.2999999999999, -173.99999999999977, -193.49999999999994, -194.79999999999995, -175.29999999999978, -185.69999999999987, -196.09999999999997, -176.60000000000005, -175.30000000000004, -188.2999999999999, -172.7, -173.3999999999999, -193.49999999999994, -177.8999999999998, -181.79999999999984, -186.9999999999999, -185.69999999999987, -153.5000000000001, -167.69999999999987, -192.19999999999993, -175.29999999999978, -158.4000000000001, -179.20000000000005, -193.49999999999994, -162.99999999999997, -183.0999999999999, -194.79999999999995, -194.79999999999995, -196.09999999999997, -184.39999999999986, -175.29999999999978, -188.2999999999999, -167.49999999999997, -186.9999999999999, -190.89999999999992, -196.09999999999997, -193.49999999999994, -188.2999999999999, -186.9999999999999, -175.29999999999978, -179.19999999999982, -194.79999999999995, -193.49999999999994, -181.79999999999984, -159.7000000000001, -196.09999999999997, -194.79999999999995, -176.5999999999998, -154.5000000000001, -153.80000000000004, -192.19999999999993, -181.79999999999984, -194.79999999999995, -183.09999999999985, -179.2, -192.19999999999993, -155.7999999999999, -183.09999999999985, -173.99999999999977, -162.3, -188.2999999999999, -188.3, -185.6999999999999, -190.89999999999992, -184.39999999999986, -193.49999999999994, -185.70000000000005, -162.2999999999998, -175.29999999999978, -186.9999999999999, -197.39999999999998, -186.9999999999999, -164.9000000000001, -192.19999999999993, -183.09999999999985, -181.79999999999984, -188.3, -177.8999999999998, -179.19999999999982, -168.80000000000007, -177.8999999999998, -180.50000000000006, -189.5999999999999, -189.5999999999999, -175.29999999999984, -188.2999999999999, -177.8999999999998, -192.19999999999993, -173.99999999999994, -189.59999999999994, -184.39999999999986, -184.39999999999986, -197.39999999999998, -176.2, -193.49999999999994, -188.2999999999999, -156.6000000000001, -185.69999999999993, -176.59999999999985, -184.40000000000003, -190.89999999999992, -193.49999999999994, -190.89999999999992, -181.79999999999984, -176.59999999999994, -185.6999999999999, -164.8999999999998, -189.59999999999994, -162.40000000000006, -188.2999999999999, -183.09999999999985, -185.69999999999987, -153.7000000000001, -176.5999999999998, -188.2999999999999, -186.9999999999999, -183.09999999999985, -168.79999999999973, -189.5999999999999, -189.5999999999999, -176.5999999999998, -192.19999999999993, -162.29999999999984, -181.79999999999984, -184.39999999999986, -194.79999999999995, -192.19999999999993, -185.69999999999987, -179.19999999999982, -163.59999999999982, -173.99999999999983, -179.19999999999982, -193.49999999999994, -197.4, -176.60000000000005, -176.5999999999998, -179.19999999999996, -180.49999999999983, -176.5999999999998, -183.09999999999985, -185.69999999999987, -179.19999999999982, -177.8999999999998, -169.89999999999984, -183.09999999999985, -170.3, -154.50000000000003, -147.10000000000014, -196.09999999999997, -156.9, -190.89999999999992, -181.79999999999984, -189.5999999999999, -181.79999999999984, -193.49999999999994, -184.39999999999986, -190.89999999999992, -187.0, -189.5999999999999, -168.6999999999999, -176.5999999999998, -176.5999999999998, -197.4, -190.90000000000003, -175.29999999999978, -176.59999999999997, -189.5999999999999, -177.8999999999998, -183.09999999999985, -176.5999999999998, -181.79999999999984, -190.89999999999992, -194.79999999999995, -180.49999999999983, -184.39999999999986, -192.19999999999993, -155.8000000000001, -190.89999999999992, -184.39999999999986, -185.69999999999987, -185.69999999999987, -189.5999999999999, -176.60000000000005, -192.19999999999993, -190.89999999999992, -185.69999999999987, -194.79999999999995, -183.09999999999985, -186.9999999999999, -184.39999999999986, -184.40000000000003, -189.59999999999997, -185.69999999999987, -180.49999999999983, -192.19999999999993, -190.90000000000003, -170.0999999999998, -180.49999999999983, -174.39999999999984, -189.5999999999999, -184.39999999999986, -185.69999999999987, -190.89999999999992, -196.09999999999997, -161.00000000000009, -192.19999999999993, -166.19999999999987, -177.8999999999998, -168.80000000000007, -179.19999999999982, -186.9999999999999, -184.39999999999986, -183.09999999999985, -192.19999999999993, -189.5999999999999, -153.90000000000006, -193.49999999999994, -186.9999999999999, -179.19999999999982, -196.09999999999997, -169.89999999999984, -188.3, -185.69999999999987, -173.99999999999977, -184.39999999999986, -190.89999999999992, -196.10000000000002, -184.39999999999986, -185.69999999999987, -194.79999999999995, -193.49999999999994, -150.5000000000001, -189.5999999999999, -192.19999999999993, -183.09999999999985, -187.00000000000003, -172.69999999999993, -172.69999999999993, -183.09999999999985, -188.2999999999999, -180.49999999999983, -185.70000000000005, -197.39999999999998, -185.69999999999987, -194.79999999999995, -181.7999999999999, -197.39999999999998, -192.19999999999993, -184.39999999999986, -179.19999999999982, -186.9999999999999, -184.39999999999986, -190.89999999999992, -197.39999999999998, -180.49999999999983, -193.5, -192.19999999999993, -190.89999999999992, -175.29999999999998, -180.49999999999983, -193.49999999999994, -196.09999999999997, -187.0, -186.99999999999991, -179.19999999999982, -190.89999999999992, -188.2999999999999, -185.69999999999987, -186.9999999999999, -177.8999999999999, -177.8999999999998, -190.89999999999992, -179.19999999999982, -180.49999999999983, -181.79999999999984, -179.19999999999982, -196.10000000000002, -192.19999999999993, -190.89999999999992, -180.49999999999983, -189.5999999999999, -190.89999999999992, -185.69999999999987, -197.39999999999998, -183.09999999999985, -172.49999999999986, -184.39999999999986, -174.00000000000006, -183.09999999999985, -184.39999999999986, -184.39999999999986, -145.70000000000016, -196.10000000000002, -181.80000000000004, -188.2999999999999, -190.89999999999992, -192.19999999999993, -189.5999999999999, -175.29999999999978, -188.2999999999999, -190.89999999999992, -185.69999999999987, -183.09999999999985, -196.09999999999997, -176.5999999999998, -192.19999999999993, -177.89999999999984, -194.79999999999995, -144.2999999999999, -181.79999999999984, -193.5, -159.7000000000001, -176.5999999999998, -179.19999999999982, -189.5999999999999, -193.49999999999994, -186.9999999999999, -176.5999999999998, -193.49999999999994, -184.39999999999986, -194.79999999999995, -166.19999999999987, -185.69999999999987, -149.30000000000013, -168.39999999999992, -190.89999999999992, -197.4, -188.2999999999999, -189.5999999999999, -189.5999999999999, -190.89999999999992, -160.5000000000001, -194.79999999999995, -183.09999999999985, -196.09999999999997, -190.89999999999992, -189.60000000000002, -177.8999999999998, -172.69999999999976, -159.7000000000001, -183.09999999999985, -188.2999999999999, -192.19999999999993, -188.2999999999999, -161.10000000000008, -197.39999999999998, -183.09999999999985, -194.79999999999995, -190.89999999999992, -184.39999999999986, -176.5999999999998, -192.19999999999993, -184.40000000000003, -194.79999999999995, -196.09999999999997, -181.79999999999984, -193.49999999999994, -189.5999999999999, -177.8999999999998, -175.29999999999987, -188.2999999999999, -184.39999999999986, -197.4, -176.5999999999998, -173.99999999999997, -192.19999999999993, -189.5999999999999, -183.09999999999985, -184.39999999999986, -175.29999999999987, -193.49999999999994, -192.19999999999993, -175.29999999999978, -170.0999999999999]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160792/160792 [==============================] - 14s 87us/step - loss: 0.8877\n",
      "Epoch 2/5\n",
      "160792/160792 [==============================] - 15s 92us/step - loss: 0.8850\n",
      "Epoch 3/5\n",
      "160792/160792 [==============================] - 15s 91us/step - loss: 0.8843\n",
      "Epoch 4/5\n",
      "160792/160792 [==============================] - 15s 93us/step - loss: 0.8839\n",
      "Epoch 5/5\n",
      "160792/160792 [==============================] - 15s 96us/step - loss: 0.8834\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  #initializer\n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='squared_hinge', optimizer=Adam()) # keras.losses.categorical_crossentropy\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores6_order = np.sort(scores)\n",
    "avg_scores6 = sum(scores)/len(scores)\n",
    "scores6_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(scores1_order,label='self-define 1')\n",
    "ax.axhline(avg_scores1, linewidth=0.5)  # color='blue', linewidth=0.5\n",
    "\n",
    "ax.plot(scores2_order, color='r',label='self-define 2')\n",
    "ax.axhline(avg_scores2, color='r',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores3_order, color='g',label='self-define 3')\n",
    "ax.axhline(avg_scores3, color='g',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores4_order, color='y',label='self-define 4')\n",
    "ax.axhline(avg_scores4, color='y',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores5_order, color='m',label='self-define 5-1')\n",
    "ax.axhline(avg_scores5, color='m',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores6_order, color='c',label='self-define 5-2')\n",
    "ax.axhline(avg_scores6, color='c',linewidth=0.5)\n",
    "\n",
    "# ax.plot(scores7_order, color='c',label='hinge')\n",
    "# ax.axhline(avg_scores7, color='c',linewidth=0.5)\n",
    "\n",
    "ax.legend(loc='lower right', prop={\"size\":12})\n",
    "ax.margins(0.05)\n",
    "#ax.set_title('results with different loss')\n",
    "ax.set_xlabel('trial')\n",
    "ax.set_ylabel('score')\n",
    "\n",
    "plt.savefig('reward.png')\n",
    "# ax.set_rasterized(True)\n",
    "# plt.savefig('loss.eps', format='eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf21",
   "language": "python",
   "name": "tf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
