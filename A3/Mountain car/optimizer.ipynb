{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "goal_steps = 200\n",
    "score_requirement = -198\n",
    "intial_games = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_preparation():\n",
    "    training_data = []\n",
    "    accepted_scores = []\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 3)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            if observation[0] > -0.2:  # delf-defined\n",
    "                reward = 1\n",
    "            \n",
    "            score += reward   \n",
    "            if done:  # done in wiki: position>0.5 \n",
    "                break\n",
    "            \n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:  # one-hot code\n",
    "                if data[1] == 1:\n",
    "                    output = [0, 1, 0]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1, 0, 0]\n",
    "                elif data[1] == 2:\n",
    "                    output = [0, 0, 1]\n",
    "                training_data.append([data[0], output])\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "    print(accepted_scores)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-186.0, -182.0, -180.0, -190.0, -190.0, -186.0, -172.0, -188.0, -190.0, -176.0, -188.0, -194.0, -176.0, -182.0, -196.0, -176.0, -178.0, -194.0, -178.0, -188.0, -170.0, -190.0, -178.0, -184.0, -194.0, -166.0, -186.0, -196.0, -162.0, -170.0, -184.0, -196.0, -196.0, -166.0, -188.0, -176.0, -178.0, -178.0, -160.0, -174.0, -188.0, -188.0, -170.0, -172.0, -178.0, -172.0, -180.0]\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 2s 203us/step - loss: 0.2275\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 0s 49us/step - loss: 0.2220\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 0s 49us/step - loss: 0.2210\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 1s 92us/step - loss: 0.2208\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 0s 47us/step - loss: 0.2205\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -131., -131., -129., -129.,\n",
       "       -129., -129., -129., -128., -128., -128., -128., -128., -128.,\n",
       "       -128., -128., -128., -128., -128., -127., -127., -127., -127.,\n",
       "       -127., -127., -127., -127., -127., -127., -127., -127., -127.,\n",
       "       -126., -126., -125., -125., -125., -125., -125., -125., -125.,\n",
       "       -124., -124., -124., -124., -124., -124., -124., -123., -123.,\n",
       "       -122., -122., -122., -122., -122., -122., -122., -122., -122.,\n",
       "       -122., -121., -121., -121., -121., -121., -121., -120., -120.,\n",
       "       -120.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam()) \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        # Uncomment this line if you want to see how our bot playing\n",
    "        # env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   #direct\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores1_order = np.sort(scores)\n",
    "avg_scores1 = sum(scores)/len(scores)\n",
    "scores1_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 1s 154us/step - loss: 0.2243\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 0s 48us/step - loss: 0.2219\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 0s 46us/step - loss: 0.2216\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 0s 46us/step - loss: 0.2214\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 0s 42us/step - loss: 0.2212\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -197., -196., -195., -190., -188.,\n",
       "       -187., -187., -187., -185., -183., -182., -182., -182., -182.,\n",
       "       -182., -181., -181., -181., -181., -180., -180., -179., -179.,\n",
       "       -179., -179., -179., -178., -178., -178., -178., -178., -178.,\n",
       "       -178., -178., -178., -178., -178., -177., -177., -177., -177.,\n",
       "       -177., -177., -177., -177., -142., -122., -113., -113., -110.,\n",
       "       -109., -108., -108., -106., -104., -104., -103., -102., -101.,\n",
       "       -100.,  -99.,  -99.,  -99.,  -99.,  -98.,  -98.,  -97.,  -97.,\n",
       "        -97.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adagrad()) \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        # Uncomment this line if you want to see how our bot playing\n",
    "        # env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   ## default reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores2_order = np.sort(scores)\n",
    "avg_scores2 = sum(scores)/len(scores)\n",
    "scores2_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 2s 190us/step - loss: 0.2272\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 0s 48us/step - loss: 0.2229\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 0s 49us/step - loss: 0.2225\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 0s 48us/step - loss: 0.2224\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 1s 64us/step - loss: 0.2223\n",
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adadelta()) \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        # Uncomment this line if you want to see how our bot playing\n",
    "        # env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   # default reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores3_order = np.sort(scores)\n",
    "avg_scores3 = sum(scores)/len(scores)\n",
    "scores3_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 2s 205us/step - loss: 0.6895\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 0s 49us/step - loss: 0.6667\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 1s 58us/step - loss: 0.6667\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 0s 52us/step - loss: 0.6667\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 0s 52us/step - loss: 0.6667\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from keras.optimizers import Adamax\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='hinge', optimizer=Adamax()) \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   ## default reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores4_order = np.sort(scores)\n",
    "avg_scores4 = sum(scores)/len(scores)\n",
    "scores4_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 2s 220us/step - loss: 0.6880\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 1s 84us/step - loss: 0.6667\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 1s 59us/step - loss: 0.6667\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 1s 81us/step - loss: 0.6667\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 0s 53us/step - loss: 0.6667\n",
      "Wall time: 16.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='hinge', optimizer=RMSprop()) \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   ## default reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores5_order = np.sort(scores)\n",
    "avg_scores5 = sum(scores)/len(scores)\n",
    "scores5_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9353/9353 [==============================] - 2s 205us/step - loss: 0.7934\n",
      "Epoch 2/5\n",
      "9353/9353 [==============================] - 1s 68us/step - loss: 0.6671\n",
      "Epoch 3/5\n",
      "9353/9353 [==============================] - 1s 63us/step - loss: 0.6667\n",
      "Epoch 4/5\n",
      "9353/9353 [==============================] - 1s 69us/step - loss: 0.6667\n",
      "Epoch 5/5\n",
      "9353/9353 [==============================] - 0s 48us/step - loss: 0.6667\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200., -200., -200., -200., -200., -200., -200., -200., -200.,\n",
       "       -200.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#from keras.optimizers import sgd\n",
    "\n",
    "def build_model(input_size, output_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_size, activation='relu'))  \n",
    "        model.add(Dense(52, activation='relu'))\n",
    "        model.add(Dense(output_size, activation='linear'))\n",
    "        model.compile(loss='hinge', optimizer='sgd') \n",
    "\n",
    "        return model\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
    "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
    "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
    "    \n",
    "    model.fit(X, y, epochs=5)   # train\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(training_data)\n",
    "\n",
    "# orginal experiment\n",
    "\n",
    "scores = []\n",
    "choices = []\n",
    "for each_game in range(100):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "#         Uncomment this line if you want to see how our bot playing\n",
    "#        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
    "        \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=reward   ## default reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "    \n",
    "scores6_order = np.sort(scores)\n",
    "avg_scores6 = sum(scores)/len(scores)\n",
    "scores6_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(scores1_order, label='Adam')\n",
    "ax.axhline(avg_scores1, linewidth=0.5)  # color='blue', linewidth=0.5\n",
    "\n",
    "ax.plot(scores2_order, color='r', label='Adagrad')\n",
    "ax.axhline(avg_scores2, color='r',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores3_order, color='g', label='Adadelta')\n",
    "ax.axhline(avg_scores3, color='g',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores4_order, color='c', label='Adamax')\n",
    "ax.axhline(avg_scores4, color='c',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores5_order, color='m', label='RMSprop')\n",
    "ax.axhline(avg_scores5, color='m',linewidth=0.5)\n",
    "\n",
    "ax.plot(scores6_order, color='y', label='sgd')\n",
    "ax.axhline(avg_scores6, color='y',linewidth=0.5)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.margins(0.05)\n",
    "#ax.set_title('results with different optimizer')\n",
    "ax.set_xlabel('trial')\n",
    "ax.set_ylabel('score')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('optimizer.png')\n",
    "# ax.set_rasterized(True)\n",
    "# plt.savefig('optimizer.eps', format='eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
